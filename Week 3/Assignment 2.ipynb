{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3210cdc-7960-4ebc-9093-f59e51199730",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "I collect a set of data ($n = 100$ observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9719fecb-729d-4318-aa91-69b66430db2c",
   "metadata": {},
   "source": [
    "## Part (a)\n",
    "\n",
    "**Suppose that the true relationship between X and Y is linear, i.e. $Y = \\beta_0 + \\beta_1X + \\epsilon$. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c2b23b-9062-49fa-8055-d78abefb75c5",
   "metadata": {},
   "source": [
    "We would expect the training RSS for the cubic regression to be lower than the training RSS for the linear regression. This is because the cubic regression is able to more accurately fit the training data points better (even though the overall realtionship is linear). Because it has more coefficients to vary, the cubic regression will overfit to the data causing its RSS to be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b834802-a606-4e6c-bb4e-b3f9b6708225",
   "metadata": {},
   "source": [
    "## Part (b)\n",
    "\n",
    "**Answer (a) using test rather than training RSS.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4582d78-a9fa-4f35-ab99-b31195723bfe",
   "metadata": {},
   "source": [
    "Because the true relationship is linear, we would expect the linear model to preform better than the cubic model on data points that was not included in the training dataset. This is because the linear model accurately reflects the true behavior of the data, so while the training RSS might be higher due to error terms, the test RSS will be lower because the cubic model will not predict new daa points as well since it overfitted to the training data. Thus the test RSS for the linear regression will be lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228e7ed-c693-4ebe-88b5-cb22f6d784cc",
   "metadata": {},
   "source": [
    "## Part (c)\n",
    "\n",
    "**Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e2f0f6-9d17-4b42-b60e-4233d5017d49",
   "metadata": {},
   "source": [
    "We would expect the cubic regression to have a lower training RSS, because it can fit to the training data better due to the extra coefficients in the model. The linear model is restricted to only one coefficient and one intercept, meaning it can't fit to an unknown relationship as well as a cubic (in general)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd001563-267f-4c6b-aa4c-baa9dddf8138",
   "metadata": {},
   "source": [
    "## Part (d)\n",
    "\n",
    "**Answer (c) using test rather than training RSS.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f26ead-9c98-4261-a49f-5f026f2117e7",
   "metadata": {},
   "source": [
    "Because we don't know the true relationship of X and Y, we can't say which one will perform better on data it has never seen before. It all depends on the actual relationship and how it comapres to the linear and cubic graphs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b7a07-eedd-4eda-8286-65cd610ac09e",
   "metadata": {},
   "source": [
    "# Exercise 7\n",
    "\n",
    "It is claimed in the text that in the case of simple linear regression of Y onto X, the $R^2$ statistic is equal to the square of the correlation between X and Y. Prove that this is the case. For simplicity, you may assume that $\\bar{x} = \\bar{y} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907074e-c291-47d9-b5c6-abdc7c4bd967",
   "metadata": {},
   "source": [
    "Because $\\bar{x} = \\bar{y} = 0$, we can say that $\\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x} = 0$, so our regression line is of the form $\\hat{y} = \\hat{\\beta_1}x$. Additionally, our expressions for $\\hat{\\beta_1}$ and TSS are simplifed to the following:\n",
    "$$\\hat{\\beta_1} = \\dfrac{\\sum x_iy_i}{\\sum x_i^2}$$\n",
    "$$TSS = \\sum y_i^2.$$\n",
    "Note that when $\\sum$ is used without bounds, it is implied that it means $\\sum\\limits_{i=1}^n$.\n",
    "\n",
    "Now we can use our simplified $\\hat{y}$ formula to find RSS:\n",
    "\n",
    "\\begin{align*}\n",
    "RSS &= \\sum (y_i - \\hat{y_i})^2 \\\\\n",
    "&= \\sum \\left(y_i -  \\dfrac{\\sum x_jy_j}{\\sum x_j^2}x_i\\right)^2 \\\\\n",
    "&= \\sum \\left(y_i^2 - 2\\dfrac{\\sum x_jy_j}{\\sum x_j^2}x_iy_i + \\left(\\dfrac{\\sum x_jy_j}{\\sum x_j^2}x_i\\right)^2\\right) \\\\\n",
    "& = \\left(\\sum y_i^2\\right) -2\\dfrac{\\sum x_jy_j}{\\sum x_j^2}\\left(\\sum x_iy_i\\right) + \\left(\\dfrac{\\sum x_jy_j}{\\sum x_j^2}\\right)^2 \\sum x_i^2\\\\\n",
    "& = TSS -2\\dfrac{\\left(\\sum x_jy_j\\right)^2}{\\sum x_j^2} + \\dfrac{\\left(\\sum x_jy_j\\right)^2}{\\sum x_j^2} \\\\\n",
    "& = TSS -\\dfrac{\\left(\\sum x_jy_j\\right)^2}{\\sum x_i^2}.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Plugging this into the formula for $R^2$ gives:\n",
    "\n",
    "\\begin{align*}\n",
    "R^2 &= \\dfrac{TSS - RSS}{TSS} \\\\\n",
    "&= \\dfrac{TSS - \\left(TSS - \\dfrac{\\left(\\sum x_jy_j\\right)^2}{\\sum x_i^2}\\right)}{\\sum y_i^2} \\\\\n",
    "&= \\dfrac{\\left(\\sum x_jy_j\\right)^2}{\\sum x_i^2\\sum y_i^2}.\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Now let's look at the correlation coefficient $r$:\n",
    "\n",
    "$$ r = \\dfrac{\\sum x_iy_i}{\\sqrt{\\sum x_i^2}\\sqrt{\\sum y_i^2}}.$$\n",
    "\n",
    "Then we square the expression to get:\n",
    "\n",
    "\\begin{align*}\n",
    "r^2 &= \\dfrac{\\left(\\sum x_iy_i\\right)^2}{\\sum x_i^2\\sum y_i^2} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "This exactly the expression we found for $R^2$!! Therefore we have probed that $\\boxed{R^2 = r^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da342bda-c627-46e0-bdf0-11cf91eec586",
   "metadata": {},
   "source": [
    "# Exercise 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ab2691-ed09-4fea-9f61-d4e1af11a531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 11</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Sales</th><th scope=col>CompPrice</th><th scope=col>Income</th><th scope=col>Advertising</th><th scope=col>Population</th><th scope=col>Price</th><th scope=col>ShelveLoc</th><th scope=col>Age</th><th scope=col>Education</th><th scope=col>Urban</th><th scope=col>US</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 9.50</td><td>138</td><td> 73</td><td>11</td><td>276</td><td>120</td><td>Bad   </td><td>42</td><td>17</td><td>Yes</td><td>Yes</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>11.22</td><td>111</td><td> 48</td><td>16</td><td>260</td><td> 83</td><td>Good  </td><td>65</td><td>10</td><td>Yes</td><td>Yes</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>10.06</td><td>113</td><td> 35</td><td>10</td><td>269</td><td> 80</td><td>Medium</td><td>59</td><td>12</td><td>Yes</td><td>Yes</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 7.40</td><td>117</td><td>100</td><td> 4</td><td>466</td><td> 97</td><td>Medium</td><td>55</td><td>14</td><td>Yes</td><td>Yes</td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 4.15</td><td>141</td><td> 64</td><td> 3</td><td>340</td><td>128</td><td>Bad   </td><td>38</td><td>13</td><td>Yes</td><td>No </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>10.81</td><td>124</td><td>113</td><td>13</td><td>501</td><td> 72</td><td>Bad   </td><td>78</td><td>16</td><td>No </td><td>Yes</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 11\n",
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & Sales & CompPrice & Income & Advertising & Population & Price & ShelveLoc & Age & Education & Urban & US\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct> & <dbl> & <dbl> & <fct> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 &  9.50 & 138 &  73 & 11 & 276 & 120 & Bad    & 42 & 17 & Yes & Yes\\\\\n",
       "\t2 & 11.22 & 111 &  48 & 16 & 260 &  83 & Good   & 65 & 10 & Yes & Yes\\\\\n",
       "\t3 & 10.06 & 113 &  35 & 10 & 269 &  80 & Medium & 59 & 12 & Yes & Yes\\\\\n",
       "\t4 &  7.40 & 117 & 100 &  4 & 466 &  97 & Medium & 55 & 14 & Yes & Yes\\\\\n",
       "\t5 &  4.15 & 141 &  64 &  3 & 340 & 128 & Bad    & 38 & 13 & Yes & No \\\\\n",
       "\t6 & 10.81 & 124 & 113 & 13 & 501 &  72 & Bad    & 78 & 16 & No  & Yes\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 11\n",
       "\n",
       "| <!--/--> | Sales &lt;dbl&gt; | CompPrice &lt;dbl&gt; | Income &lt;dbl&gt; | Advertising &lt;dbl&gt; | Population &lt;dbl&gt; | Price &lt;dbl&gt; | ShelveLoc &lt;fct&gt; | Age &lt;dbl&gt; | Education &lt;dbl&gt; | Urban &lt;fct&gt; | US &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 |  9.50 | 138 |  73 | 11 | 276 | 120 | Bad    | 42 | 17 | Yes | Yes |\n",
       "| 2 | 11.22 | 111 |  48 | 16 | 260 |  83 | Good   | 65 | 10 | Yes | Yes |\n",
       "| 3 | 10.06 | 113 |  35 | 10 | 269 |  80 | Medium | 59 | 12 | Yes | Yes |\n",
       "| 4 |  7.40 | 117 | 100 |  4 | 466 |  97 | Medium | 55 | 14 | Yes | Yes |\n",
       "| 5 |  4.15 | 141 |  64 |  3 | 340 | 128 | Bad    | 38 | 13 | Yes | No  |\n",
       "| 6 | 10.81 | 124 | 113 | 13 | 501 |  72 | Bad    | 78 | 16 | No  | Yes |\n",
       "\n"
      ],
      "text/plain": [
       "  Sales CompPrice Income Advertising Population Price ShelveLoc Age Education\n",
       "1  9.50 138        73    11          276        120   Bad       42  17       \n",
       "2 11.22 111        48    16          260         83   Good      65  10       \n",
       "3 10.06 113        35    10          269         80   Medium    59  12       \n",
       "4  7.40 117       100     4          466         97   Medium    55  14       \n",
       "5  4.15 141        64     3          340        128   Bad       38  13       \n",
       "6 10.81 124       113    13          501         72   Bad       78  16       \n",
       "  Urban US \n",
       "1 Yes   Yes\n",
       "2 Yes   Yes\n",
       "3 Yes   Yes\n",
       "4 Yes   Yes\n",
       "5 Yes   No \n",
       "6 No    Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ISLR)\n",
    "head(Carseats)\n",
    "\n",
    "attach(Carseats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee0901-ab4d-4ae8-aa61-ef33b3309cd2",
   "metadata": {},
   "source": [
    "## Part(a)\n",
    "\n",
    "**Fit a multiple regression model to predict Sales using Price, Urban, and US.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4c5a77-90c3-44e1-90a7-d0987cbed972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Sales ~ Price + Urban + US)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.9206 -1.6220 -0.0564  1.5786  7.0581 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 13.043469   0.651012  20.036  < 2e-16 ***\n",
       "Price       -0.054459   0.005242 -10.389  < 2e-16 ***\n",
       "UrbanYes    -0.021916   0.271650  -0.081    0.936    \n",
       "USYes        1.200573   0.259042   4.635 4.86e-06 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 2.472 on 396 degrees of freedom\n",
       "Multiple R-squared:  0.2393,\tAdjusted R-squared:  0.2335 \n",
       "F-statistic: 41.52 on 3 and 396 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = lm(Sales ~ Price + Urban + US)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bdfd73-a764-49bd-990e-5965ea88305a",
   "metadata": {},
   "source": [
    "## Part (b)\n",
    "\n",
    "**Provide an interpretation of each coefficient in the model. Be careful—some of the variables in the model are qualitative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50d8c04-6ffe-456a-8c64-946d6b8ea617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Yes\n",
      "No    0\n",
      "Yes   1\n",
      "    Yes\n",
      "No    0\n",
      "Yes   1\n"
     ]
    }
   ],
   "source": [
    "print(contrasts(Urban))\n",
    "print(contrasts(US))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e7c2c1-eca5-415b-a751-7a353d523a0d",
   "metadata": {},
   "source": [
    "The coefficient for Price is negative, meaning as price increases sales decrease (which makes sense). The coefficient for UrbanYes is -0.02, so if the store is urban then its sales decrease. The coefficient for USYes however is positive, meaning that if a store is in the US then it has more sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd99689c-1bb6-4e96-9d77-b4f2b05cfb3c",
   "metadata": {},
   "source": [
    "## Part (c)\n",
    "\n",
    "**Write out the model in equation form, being careful to handle the qualitative variables properly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e58d2-b83e-4a28-a491-e3b429744541",
   "metadata": {},
   "source": [
    "$\\text{Sales} \\approx -0.05\\cdot\\text{Price} - 0.02\\cdot\\text{UrbanYes} + 1.20\\cdot\\text{USYes}$\n",
    "\n",
    "where UrbanYes is 1 if it is urban and 0 otherwise, and USYes is 1 if in the US and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce2a4b-c771-4d16-aeba-9a2cc59da4f7",
   "metadata": {},
   "source": [
    "## Part (d)\n",
    "\n",
    "**For which of the predictors can you reject the null hypothesis $H_0: \\beta_j=0$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32adb21c-a8d9-4ee6-ab80-e5054b010bd6",
   "metadata": {},
   "source": [
    "The p-value for everything except UrbanYes is extremely low, so we can reject the null hypothesis for Price and UrbanYes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593392af-c943-4fbf-9265-d37f6685e099",
   "metadata": {},
   "source": [
    "## Part (e)\n",
    "\n",
    "**On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c334229-4451-4d51-8fd2-9b02405bc4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Sales ~ Price + US)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.9269 -1.6286 -0.0574  1.5766  7.0515 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 13.03079    0.63098  20.652  < 2e-16 ***\n",
       "Price       -0.05448    0.00523 -10.416  < 2e-16 ***\n",
       "USYes        1.19964    0.25846   4.641 4.71e-06 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 2.469 on 397 degrees of freedom\n",
       "Multiple R-squared:  0.2393,\tAdjusted R-squared:  0.2354 \n",
       "F-statistic: 62.43 on 2 and 397 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = lm(Sales~Price+US)\n",
    "summary(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d057ab5-0983-405b-aac1-91f8e2d6921d",
   "metadata": {},
   "source": [
    "## Part (f)\n",
    "\n",
    "**How well do the models in (a) and (e) fit the data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985196ac-435a-45e0-8751-2d65db38e482",
   "metadata": {},
   "source": [
    "The $R^2$ term for the models in both (a) and are 0.23, which means that only 23% of the variation in Sales is explained by the predictors. The exclusion of the Urban variable doesn't change the fit significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cda536-4d59-438e-a572-f5b40eb0d8fa",
   "metadata": {},
   "source": [
    "## Part (g)\n",
    "\n",
    "**Using the model from (e), obtain 95 % confidence intervals for the coefficient(s).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d05bb46d-b205-4318-88a1-9402719db971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  2.5 %      97.5 %\n",
      "(Intercept) 11.79032020 14.27126531\n",
      "Price       -0.06475984 -0.04419543\n",
      "USYes        0.69151957  1.70776632\n"
     ]
    }
   ],
   "source": [
    "print(confint(model1, level=0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03386f5e-0d69-4bf7-b9ab-626916e50e68",
   "metadata": {},
   "source": [
    "## Part (h)\n",
    "\n",
    "**Is there evidence of outliers or high leverage observations in the model from (e)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6149b507-1cf5-4a38-afb7-773d408d35c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>51:</strong> -2.81102167244627"
      ],
      "text/latex": [
       "\\textbf{51:} -2.81102167244627"
      ],
      "text/markdown": [
       "**51:** -2.81102167244627"
      ],
      "text/plain": [
       "       51 \n",
       "-2.811022 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>377:</strong> 2.86508213825242"
      ],
      "text/latex": [
       "\\textbf{377:} 2.86508213825242"
      ],
      "text/markdown": [
       "**377:** 2.86508213825242"
      ],
      "text/plain": [
       "     377 \n",
       "2.865082 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>43:</strong> 0.0433376570371785"
      ],
      "text/latex": [
       "\\textbf{43:} 0.0433376570371785"
      ],
      "text/markdown": [
       "**43:** 0.0433376570371785"
      ],
      "text/plain": [
       "        43 \n",
       "0.04333766 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.015\n"
     ]
    }
   ],
   "source": [
    "st_res = rstandard(model1)\n",
    "st_res[which.min(st_res)]\n",
    "st_res[which.max(st_res)]\n",
    "\n",
    "lev = hatvalues(model1)\n",
    "lev[which.max(lev)]\n",
    "print(2*(2+1)/nrow(Carseats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006d80a-ffc5-45a6-ba50-6952cf219c1b",
   "metadata": {},
   "source": [
    "We see that the lowest and highest studentized residual is -2.8 and 2.9, both of which are within -3 and 3, so no significant outliers there. We see that twice the average leverage is 0.015, but the max leverage is 0.04, meaning there are some points that have a significantly high leverage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8762147e-a072-43cb-94d4-59cf308af223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>43</dt><dd>0.0433376570371785</dd><dt>126</dt><dd>0.0259661351134241</dd><dt>156</dt><dd>0.016106161622167</dd><dt>157</dt><dd>0.0153555754048395</dd><dt>160</dt><dd>0.0157073653087183</dd><dt>166</dt><dd>0.0285666078977165</dd><dt>172</dt><dd>0.0210140057511345</dd><dt>175</dt><dd>0.0296867177031533</dd><dt>192</dt><dd>0.0180391028373988</dd><dt>204</dt><dd>0.0153555754048395</dd><dt>209</dt><dd>0.0182347179910024</dd><dt>270</dt><dd>0.0191949376316542</dd><dt>273</dt><dd>0.0186873442250878</dd><dt>314</dt><dd>0.0231647047366309</dd><dt>316</dt><dd>0.0170488131217078</dd><dt>357</dt><dd>0.0182789444516194</dd><dt>366</dt><dd>0.0173988378853422</dd><dt>368</dt><dd>0.0237070475051107</dd><dt>384</dt><dd>0.0165139295890552</dd><dt>387</dt><dd>0.0165546179328228</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[43] 0.0433376570371785\n",
       "\\item[126] 0.0259661351134241\n",
       "\\item[156] 0.016106161622167\n",
       "\\item[157] 0.0153555754048395\n",
       "\\item[160] 0.0157073653087183\n",
       "\\item[166] 0.0285666078977165\n",
       "\\item[172] 0.0210140057511345\n",
       "\\item[175] 0.0296867177031533\n",
       "\\item[192] 0.0180391028373988\n",
       "\\item[204] 0.0153555754048395\n",
       "\\item[209] 0.0182347179910024\n",
       "\\item[270] 0.0191949376316542\n",
       "\\item[273] 0.0186873442250878\n",
       "\\item[314] 0.0231647047366309\n",
       "\\item[316] 0.0170488131217078\n",
       "\\item[357] 0.0182789444516194\n",
       "\\item[366] 0.0173988378853422\n",
       "\\item[368] 0.0237070475051107\n",
       "\\item[384] 0.0165139295890552\n",
       "\\item[387] 0.0165546179328228\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "43\n",
       ":   0.0433376570371785126\n",
       ":   0.0259661351134241156\n",
       ":   0.016106161622167157\n",
       ":   0.0153555754048395160\n",
       ":   0.0157073653087183166\n",
       ":   0.0285666078977165172\n",
       ":   0.0210140057511345175\n",
       ":   0.0296867177031533192\n",
       ":   0.0180391028373988204\n",
       ":   0.0153555754048395209\n",
       ":   0.0182347179910024270\n",
       ":   0.0191949376316542273\n",
       ":   0.0186873442250878314\n",
       ":   0.0231647047366309316\n",
       ":   0.0170488131217078357\n",
       ":   0.0182789444516194366\n",
       ":   0.0173988378853422368\n",
       ":   0.0237070475051107384\n",
       ":   0.0165139295890552387\n",
       ":   0.0165546179328228\n",
       "\n"
      ],
      "text/plain": [
       "        43        126        156        157        160        166        172 \n",
       "0.04333766 0.02596614 0.01610616 0.01535558 0.01570737 0.02856661 0.02101401 \n",
       "       175        192        204        209        270        273        314 \n",
       "0.02968672 0.01803910 0.01535558 0.01823472 0.01919494 0.01868734 0.02316470 \n",
       "       316        357        366        368        384        387 \n",
       "0.01704881 0.01827894 0.01739884 0.02370705 0.01651393 0.01655462 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lev[lev > 2*3/nrow(Carseats)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7226bb5c-3b19-45c3-8070-d18649e49b21",
   "metadata": {},
   "source": [
    "The values in bold above are the row index of the store, and the corresponding decimal is the leverage associated with it. These are all the stores with a leverage greater than twice the average (high leverage)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
